---
layout: post
title: MarI/O & Deep Learning in Video Games
---

Perhaps inspired by DeepMind’s success applying deep learning to classic Atari games, YouTuber SethBling trained a neural network, dubbed MarI/O, to play the well-known Super Mario World level Donut Plains 1. MarI/O is based off of work published in the NeuroEvolution of Augmenting Topologies (NEAT) paper, and its code is comprised of a combination of neural networks and genetic algorithms. As demonstrated in the video, MarI/O learned to play the game with quite a bit of efficiency after just 24 hours of training, which, in this case, was equivalent to 30 or so generations of “neuro-evolution”.

An important thing to note here, however, is that MarI/O was trained on Donut Plains 1 alone and played on Donut Plains 1 alone. This, with regards to the neural network, presents the problem of “overfitting”, meaning that the program has not been “generalized” enough for success on other levels. Indeed, in this follow-up video, SethBling himself shows MarI/O, despite additional learning, proving unable to complete the Donut Plains 4 level due to an unfamiliar pipe.

Regardless, as someone who grew up playing Super Mario World – and a whole lot of other games – I’m excited by the prospect of machine learning in video games. MarI/O discovered a jump trick previously unknown to SethBling and other speedrunners. And AlphaGo stunned Lee Sedol – and the whole world – with a Game 2 move that was described as “humanly inconceivable”. These results go to the show the incredible potential for AI to push the existing boundaries and teach us something new in domains – like video games, among others – that we consider so familiar.

Additionally, in September of 2016, Google DeepMind presented WaveNet, a generative model for raw audio, which according to their press release, “mimics any human voice and which sounds more natural than the best existing Text-to-Speech systems.” This, in my opinion, represents a whole new frontier in machine learning research and opens the door for some interesting applications, particularly in animation and video games. In fact, based on the published results, it would not be farfetched to anticipate, in the near future, real-time, human-like language translation; on-the-fly voice dialogue for non-player video game characters (NPC); or general speech synthesis capabilities using the human voices of our choice.

Again, whether it be in healthcare, self-driving cars, or even video games, new works and discoveries in deep learning indicate that AI is prime to disrupt the status quo for the better – and I’m excited to see what the results will look like.

P.S. Watch out South Koreans. DeepMind is coming for SC2 next.
